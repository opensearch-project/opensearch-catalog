version: "2"
s3-log-pipeline:
  source:
    s3:
      # Prevent data loss by only considering logs to be processed successfully after they are received by the opensearch sink
      acknowledgments: true
      notification_type: "sqs"
      compression: "none"
      notification_source: "eventbridge"
      codec:
        parquet:
      sqs:
        # Provide a SQS Queue URL to read from
        queue_url: "https://sqs.ap-southeast-1.amazonaws.com/111111111111/AmazonSecurityLake-43b6b551-2a36-45f3-bb40-bd11d35431d9-Main-Queue"
        # Modify the visibility_timeout of the sqs messages depending on the size of your parquet or avro S3 objects.
        # Objects that are small (< 0.5 GB) and evenly distributed in size will result in the best performance
        # It is recommended to allocate a minimum of 30 seconds, and to add 30 seconds for every 0.25 GB of data in each S3 Object
        visibility_timeout: "60s"
        # Enable this flag to allow the visibility timeout to be extended if an object has not yet finished processing.
        # This helps prevent duplicate processing of SQS messages when the visibility timeout is lower than the amount of time required to process an object.
        visibility_duplication_protection: true
      aws:
        # Provide the region to use for aws credentials
        region: "ap-southeast-1"
        # Provide the role to assume for requests to SQS and S3
        sts_role_arn: "arn:aws:iam::222222222222:role/os-asl-test-domain-11aug-pipeline-role"
  processor:
    - drop_events:
        drop_when: '/status_code != "OK" and /metadata/product/name == "Amazon VPC"'
    - lowercase_string:
        with_keys: [ "/metadata/product/name", "/class_name" ]
    - substitute_string:
        entries:
          - source: "/metadata/product/name"
            from: "\\s"
            to: "_"
          - source: "/class_name"
            from: "\\s"
            to: "_"
    - delete_entries:
        with_keys: [ "s3" ]
  sink:
    - opensearch:
        # Provide an AWS OpenSearch Service domain endpoint
        hosts: [ "https://search-os-asl**************.aos.ap-southeast-1.on.aws" ]
        aws:
          # Provide a Role ARN with access to the domain. This role should have a trust relationship with osis-pipelines.amazonaws.com
          sts_role_arn: "arn:aws:iam::222222222222:role/os-asl-test-domain-11aug-pipeline-role"
          # Provide the region of the domain.
          region: "ap-southeast-1"
          # Enable the 'serverless' flag if the sink is an Amazon OpenSearch Serverless collection
          serverless: false
          # serverless_options:
            # Specify a name here to create or update network policy for the serverless collection
            # network_policy_name: "network-policy-name"
        index: "ocsf-${/metadata/version}-${/class_uid}-${/class_name}"
        # Enable the 'distribution_version' setting if the AWS OpenSearch Service domain is of version Elasticsearch 6.x
        # distribution_version: "es6"
        # Enable and switch the 'enable_request_compression' flag if the default compression setting is changed in the domain. See https://docs.aws.amazon.com/opensearch-service/latest/developerguide/gzip.html
        # enable_request_compression: true/false
        # Optional: Enable the S3 DLQ to capture any failed requests in an S3 bucket. Delete this entire block if you don't want a DLQ.
        # dlq:
        #   s3:
        #     # Provide an S3 bucket
        #     bucket: "<<your-dlq-bucket-name>>"
        #     # Provide a key path prefix for the failed requests
        #     # key_path_prefix: "s3-log-pipeline/dlq"
        #     # Provide the region of the bucket.
        #     region: "<<us-east-1>>"
        #     # Provide a Role ARN with access to the bucket. This role should have a trust relationship with osis-pipelines.amazonaws.com
        #     sts_role_arn: "<<arn:aws:iam::123456789012:role/Example-Role>>"
